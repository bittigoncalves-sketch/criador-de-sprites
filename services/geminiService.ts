
import { GoogleGenAI, Modality, GenerateContentResponse } from "@google/genai";

// This is a placeholder for the API key. In a real environment, it should be securely managed.
const API_KEY = process.env.API_KEY;

if (!API_KEY) {
    console.warn("API_KEY is not set. Please set the environment variable.");
}

const getAiClient = () => new GoogleGenAI({ apiKey: API_KEY });

const fileToGenerativePart = async (file: File) => {
  const base64EncodedDataPromise = new Promise<string>((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
    reader.readAsDataURL(file);
  });
  return {
    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
  };
};

export const generateImageFromText = async (prompt: string, aspectRatio: string): Promise<string> => {
    const ai = getAiClient();
    const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt,
        config: {
            numberOfImages: 1,
            outputMimeType: 'image/jpeg',
            aspectRatio: aspectRatio as "1:1" | "3:4" | "4:3" | "9:16" | "16:9",
        },
    });

    const base64ImageBytes = response.generatedImages[0].image.imageBytes;
    return `data:image/jpeg;base64,${base64ImageBytes}`;
};


export const analyzeImageContent = async (imageFile: File, prompt: string): Promise<string> => {
    const ai = getAiClient();
    const imagePart = await fileToGenerativePart(imageFile);
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [imagePart, { text: prompt }] },
    });
    return response.text;
};

export const editImageWithPrompt = async (imageFile: File, prompt: string): Promise<string> => {
    const ai = getAiClient();
    const imagePart = await fileToGenerativePart(imageFile);
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: {
            parts: [imagePart, { text: prompt }],
        },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });

    for (const part of response.candidates?.[0]?.content.parts ?? []) {
        if (part.inlineData) {
            const base64ImageBytes: string = part.inlineData.data;
            return `data:${part.inlineData.mimeType};base64,${base64ImageBytes}`;
        }
    }
    throw new Error('No image generated by the model.');
};


export const generateSpriteSheet = async (referenceFile: File, animationPrompt: string, frameCount: number = 4): Promise<string[]> => {
    const results: string[] = [];
    for (let i = 1; i <= frameCount; i++) {
        const prompt = `Based on the reference character, create frame ${i} of a ${frameCount}-frame animation for "${animationPrompt}". Isolate the character on a transparent background.`;
        const imageUrl = await editImageWithPrompt(referenceFile, prompt);
        results.push(imageUrl);
    }
    return results;
};


export const generateVideoFromImage = async (imageFile: File, prompt: string, aspectRatio: '16:9' | '9:16') => {
    const ai = getAiClient();
    const base64EncodedDataPromise = new Promise<string>((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
        reader.readAsDataURL(imageFile);
    });
    const base64Data = await base64EncodedDataPromise;

    let operation = await ai.models.generateVideos({
        model: 'veo-3.1-fast-generate-preview',
        prompt,
        image: {
            imageBytes: base64Data,
            mimeType: imageFile.type,
        },
        config: {
            numberOfVideos: 1,
            resolution: '720p',
            aspectRatio: aspectRatio
        }
    });
    return operation;
};

export const checkVideoOperationStatus = async (operation: any) => {
    const ai = getAiClient();
    return await ai.operations.getVideosOperation({ operation });
};


let chatInstance: any = null;

export const startChat = () => {
    const ai = getAiClient();
    chatInstance = ai.chats.create({
        model: 'gemini-2.5-flash',
    });
};

export const sendMessageToChat = async (message: string, useSearch: boolean, useThinking: boolean): Promise<GenerateContentResponse> => {
    const ai = getAiClient();
    
    if (useThinking) {
         return ai.models.generateContent({
            model: 'gemini-2.5-pro',
            contents: message,
            config: {
                thinkingConfig: { thinkingBudget: 32768 }
            }
        });
    }
    
    if (useSearch) {
        return ai.models.generateContent({
           model: "gemini-2.5-flash",
           contents: message,
           config: {
             tools: [{googleSearch: {}}],
           },
        });
    }

    if (!chatInstance) {
        startChat();
    }
    return await chatInstance.sendMessage({ message });
};
